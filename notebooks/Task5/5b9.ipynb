{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divided-commercial",
   "metadata": {},
   "source": [
    "# ix. Attacker estimated age. You will use the USC Data Science AgePredictor, here: https://github.com/USCDataScience/AgePredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-literacy",
   "metadata": {},
   "source": [
    "## 1. Download and init git repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "charitable-second",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import git\n",
    "\n",
    "git.Git(\"Downloads/\").clone(\"https://github.com/USCDataScience/AgePredictor.git\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "foreign-carter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[██████████████████████████████████████████████████]\n"
     ]
    }
   ],
   "source": [
    "from utils import download    \n",
    "download('https://archive.apache.org/dist/spark/spark-2.0.0/spark-2.0.0-bin-hadoop2.7.tgz', 'Downloads/spark-2.0.0-bin-hadoop2.7.tgz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-membrane",
   "metadata": {},
   "source": [
    "Follow Pre-requisites [here](https://github.com/USCDataScience/AgePredictor#pre-requisites) to init the repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-moscow",
   "metadata": {},
   "source": [
    "## 2. Train with my own dataset\n",
    "[Blog Authorship Corpus](https://www.kaggle.com/rtatman/blog-authorship-corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "serial-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "kaggle.api.dataset_download_files('rtatman/blog-authorship-corpus', path='Downloads/', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "advised-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Downloads/blogtext.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-geology",
   "metadata": {},
   "source": [
    "80\\% train, 10\\% test, 10% eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "considerable-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_train, df_test, df_eval = np.split(df, [int(.8*len(df)), int(.9*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "pressing-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['age', 'text']].to_csv('Downloads/AgePredictorTrain.txt', sep='\\t', index=False, header=False)\n",
    "df_test[['age', 'text']].to_csv('Downloads/AgePredictorTest.txt', sep='\\t', index=False, header=False)\n",
    "df_eval[['age', 'text']].to_csv('Downloads/AgePredictorEval.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-wiring",
   "metadata": {},
   "source": [
    "### Training output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-buddy",
   "metadata": {},
   "source": [
    "```bash\n",
    "~/Documents/GitHub/DSCI-550-Assignment-1/notebooks/Task5/Downloads/AgePredictor master* 20s\n",
    "❯ bin/authorage AgeClassifyTrainer -model model/anthony-ageClassify.bin -lang en -data ../AgePredictorTrain.txt -encoding UTF-8\n",
    "Sorting and merging events... done. Reduced 541390 events to 502684.\n",
    "Done indexing.\n",
    "Incorporating indexed data for training...\n",
    "done.\n",
    "\tNumber of Event Tokens: 502684\n",
    "\t    Number of Outcomes: 4\n",
    "\t  Number of Predicates: 379171\n",
    "...done.\n",
    "Computing model parameters ...\n",
    "Performing 100 iterations.\n",
    "  1:  ... loglikelihood=-750525.9041660022\t0.3393616431777462\n",
    "  2:  ... loglikelihood=-750331.720250516\t0.5272040488372522\n",
    "  3:  ... loglikelihood=-750139.428576278\t0.5272890153124365\n",
    "  4:  ... loglikelihood=-749948.8676680943\t0.5273573579120412\n",
    "  5:  ... loglikelihood=-749759.89569118\t0.5275790095864349\n",
    "  6:  ... loglikelihood=-749572.3985784702\t0.5276750586453388\n",
    "  7:  ... loglikelihood=-749386.2866187957\t0.5277470954395168\n",
    "  8:  ... loglikelihood=-749201.4887951099\t0.5278080496499751\n",
    "  9:  ... loglikelihood=-749017.9478383606\t0.5278726980550066\n",
    " 10:  ... loglikelihood=-748835.6164996169\t0.5279742884057703\n",
    " 11:  ... loglikelihood=-748654.4548772399\t0.5280167716433625\n",
    " 12:  ... loglikelihood=-748474.428533602\t0.5280832671456805\n",
    " 13:  ... loglikelihood=-748295.5071696005\t0.5281516097452853\n",
    " 14:  ... loglikelihood=-748117.6636866183\t0.5282088697611703\n",
    " 15:  ... loglikelihood=-747940.8735138841\t0.5282790594580616\n",
    " 16:  ... loglikelihood=-747765.1141196891\t0.5283677201278192\n",
    " 17:  ... loglikelihood=-747590.3646493441\t0.5284379098247105\n",
    " 18:  ... loglikelihood=-747416.6056525568\t0.5284822401595892\n",
    " 19:  ... loglikelihood=-747243.8188739385\t0.5285265704944679\n",
    " 20:  ... loglikelihood=-747071.9870892869\t0.5285579711483404\n",
    " 21:  ... loglikelihood=-746901.0939754578\t0.5286133840669388\n",
    " 22:  ... loglikelihood=-746731.1240048044\t0.5286761853746836\n",
    " 23:  ... loglikelihood=-746562.0623586982\t0.5287112802231293\n",
    " 24:  ... loglikelihood=-746393.8948556933\t0.5287666931417278\n",
    " 25:  ... loglikelihood=-746226.6078906358\t0.5287962466983136\n",
    " 26:  ... loglikelihood=-746060.1883829521\t0.5288682834924916\n",
    " 27:  ... loglikelihood=-745894.6237324171\t0.5289163080219436\n",
    " 28:  ... loglikelihood=-745729.9017802995\t0.5289864977188349\n",
    " 29:  ... loglikelihood=-745566.0107758992\t0.529004968691701\n",
    " 30:  ... loglikelihood=-745402.9393466851\t0.5290437577347199\n",
    " 31:  ... loglikelihood=-745240.6764722357\t0.5290917822641719\n",
    " 32:  ... loglikelihood=-745079.2114608131\t0.5291305713071908\n",
    " 33:  ... loglikelihood=-744918.5339284489\t0.5291619719610632\n",
    " 34:  ... loglikelihood=-744758.6337802025\t0.5292450913389608\n",
    " 35:  ... loglikelihood=-744599.5011934408\t0.5293115868412789\n",
    " 36:  ... loglikelihood=-744441.1266022155\t0.5293836236354569\n",
    " 37:  ... loglikelihood=-744283.5006837694\t0.5294242597757624\n",
    " 38:  ... loglikelihood=-744126.6143455775\t0.5294981436672269\n",
    " 39:  ... loglikelihood=-743970.4587138882\t0.5295369327102458\n",
    " 40:  ... loglikelihood=-743815.0251232547\t0.5295757217532647\n",
    " 41:  ... loglikelihood=-743660.3051066883\t0.529603428212564\n",
    " 42:  ... loglikelihood=-743506.2903865891\t0.5296773121040285\n",
    " 43:  ... loglikelihood=-743352.9728666474\t0.5297364192172002\n",
    " 44:  ... loglikelihood=-743200.3446242203\t0.5297825966493656\n",
    " 45:  ... loglikelihood=-743048.3979029261\t0.5298417037625371\n",
    " 46:  ... loglikelihood=-742897.1251062009\t0.5299118934594285\n",
    " 47:  ... loglikelihood=-742746.5187913249\t0.5299654592807403\n",
    " 48:  ... loglikelihood=-742596.5716631565\t0.5300042483237593\n",
    " 49:  ... loglikelihood=-742447.2765692215\t0.5300374960749182\n",
    " 50:  ... loglikelihood=-742298.6264943093\t0.5300762851179371\n",
    " 51:  ... loglikelihood=-742150.6145559786\t0.5301446277175419\n",
    " 52:  ... loglikelihood=-742003.2339997459\t0.530225899998153\n",
    " 53:  ... loglikelihood=-741856.4781952485\t0.5302813129167513\n",
    " 54:  ... loglikelihood=-741710.3406318339\t0.530316407765197\n",
    " 55:  ... loglikelihood=-741564.814915037\t0.530388444559375\n",
    " 56:  ... loglikelihood=-741419.8947630487\t0.5304660226454128\n",
    " 57:  ... loglikelihood=-741275.5740030467\t0.5304881878128521\n",
    " 58:  ... loglikelihood=-741131.846568168\t0.5305048116884317\n",
    " 59:  ... loglikelihood=-740988.7064942821\t0.5305454478287371\n",
    " 60:  ... loglikelihood=-740846.1479172898\t0.5305897781636159\n",
    " 61:  ... loglikelihood=-740704.1650699949\t0.5306414968876411\n",
    " 62:  ... loglikelihood=-740562.7522796699\t0.5306692033469402\n",
    " 63:  ... loglikelihood=-740421.9039653819\t0.5306987569035261\n",
    " 64:  ... loglikelihood=-740281.6146356766\t0.5307449343356915\n",
    " 65:  ... loglikelihood=-740141.8788860223\t0.5307966530597167\n",
    " 66:  ... loglikelihood=-740002.6913967326\t0.5308280537135891\n",
    " 67:  ... loglikelihood=-739864.0469306963\t0.5308391362973088\n",
    " 68:  ... loglikelihood=-739725.9403313769\t0.5308797724376143\n",
    " 69:  ... loglikelihood=-739588.3665207778\t0.5309130201887733\n",
    " 70:  ... loglikelihood=-739451.3204975327\t0.5309739743992317\n",
    " 71:  ... loglikelihood=-739314.7973350871\t0.5309979866639576\n",
    " 72:  ... loglikelihood=-739178.7921798545\t0.5310607879717024\n",
    " 73:  ... loglikelihood=-739043.3002494994\t0.5310700234581356\n",
    " 74:  ... loglikelihood=-738908.3168314848\t0.5310811060418552\n",
    " 75:  ... loglikelihood=-738773.8372811669\t0.5311051183065812\n",
    " 76:  ... loglikelihood=-738639.857020428\t0.5311198950848741\n",
    " 77:  ... loglikelihood=-738506.3715362513\t0.5311420602523135\n",
    " 78:  ... loglikelihood=-738373.3763791547\t0.5311900847817654\n",
    " 79:  ... loglikelihood=-738240.8671618095\t0.5312436506030772\n",
    " 80:  ... loglikelihood=-738108.8395578169\t0.5312658157705167\n",
    " 81:  ... loglikelihood=-737977.289300368\t0.5312916751325293\n",
    " 82:  ... loglikelihood=-737846.2121807565\t0.5313544764402741\n",
    " 83:  ... loglikelihood=-737715.6040476356\t0.5313747945104269\n",
    " 84:  ... loglikelihood=-737585.4608053744\t0.5313988067751528\n",
    " 85:  ... loglikelihood=-737455.7784131458\t0.5314228190398789\n",
    " 86:  ... loglikelihood=-737326.5528838416\t0.5314837732503371\n",
    " 87:  ... loglikelihood=-737197.7802828625\t0.5315262564879292\n",
    " 88:  ... loglikelihood=-737069.4567271755\t0.531570586822808\n",
    " 89:  ... loglikelihood=-736941.5783843228\t0.5315853636011009\n",
    " 90:  ... loglikelihood=-736814.1414713324\t0.5316075287685402\n",
    " 91:  ... loglikelihood=-736687.142253883\t0.5316426236169859\n",
    " 92:  ... loglikelihood=-736560.577045206\t0.5316814126600048\n",
    " 93:  ... loglikelihood=-736434.4422055669\t0.5317497552596095\n",
    " 94:  ... loglikelihood=-736308.7341408504\t0.5317866972053418\n",
    " 95:  ... loglikelihood=-736183.4493021487\t0.5318162507619276\n",
    " 96:  ... loglikelihood=-736058.5841847004\t0.5318402630266537\n",
    " 97:  ... loglikelihood=-735934.1353272564\t0.5319122998208315\n",
    " 98:  ... loglikelihood=-735810.099311111\t0.5319400062801308\n",
    " 99:  ... loglikelihood=-735686.4727594428\t0.5320065017824489\n",
    "100:  ... loglikelihood=-735563.2523366039\t0.5320508321173276\n",
    "Writing age classifier model ... done (5.815s)\n",
    "\n",
    "Wrote age classifier model to\n",
    "path: /Users/anthony/Documents/GitHub/DSCI-550-Assignment-1/notebooks/Task5/Downloads/AgePredictor/model/anthony-ageClassify.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-japan",
   "metadata": {},
   "source": [
    "### Evaluation results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-filename",
   "metadata": {},
   "source": [
    "```bash\n",
    "~/Documents/GitHub/DSCI-550-Assignment-1/notebooks/Task5/Downloads/AgePredictor master* 14m 37s\n",
    "❯ bin/authorage AgeClassifyEvaluator -model model/anthony-ageClassify.bin -data\n",
    "../AgePredictorTest.txt -encoding UTF-8\n",
    "current: 2740.3 doc/s avg: 2740.3 doc/s total: 2754 doc\n",
    "current: 3886.2 doc/s avg: 3304.5 doc/s total: 6619 doc\n",
    "current: 3270.5 doc/s avg: 3293.8 doc/s total: 9898 doc\n",
    "current: 3479.5 doc/s avg: 3340.2 doc/s total: 13374 doc\n",
    "current: 3092.1 doc/s avg: 3290.6 doc/s total: 16463 doc\n",
    "current: 4432.1 doc/s avg: 3481.1 doc/s total: 20904 doc\n",
    "current: 2991.0 doc/s avg: 3410.6 doc/s total: 23895 doc\n",
    "current: 1367.0 doc/s avg: 3155.5 doc/s total: 25263 doc\n",
    "current: 4312.9 doc/s avg: 3283.7 doc/s total: 29563 doc\n",
    "current: 4034.9 doc/s avg: 3359.0 doc/s total: 33607 doc\n",
    "current: 3322.6 doc/s avg: 3355.8 doc/s total: 36924 doc\n",
    "current: 3767.0 doc/s avg: 3390.2 doc/s total: 40692 doc\n",
    "current: 4163.5 doc/s avg: 3449.9 doc/s total: 44869 doc\n",
    "current: 3868.9 doc/s avg: 3479.8 doc/s total: 48735 doc\n",
    "current: 3102.1 doc/s avg: 3454.7 doc/s total: 51834 doc\n",
    "current: 3025.1 doc/s avg: 3427.9 doc/s total: 54853 doc\n",
    "current: 4277.4 doc/s avg: 3478.0 doc/s total: 59140 doc\n",
    "current: 4556.9 doc/s avg: 3538.1 doc/s total: 63707 doc\n",
    "\n",
    "\n",
    "Average: 3574.9 doc/s\n",
    "Total: 67744 doc\n",
    "Runtime: 18.95s\n",
    "\n",
    "Accuracy: 0.5623016400218472\n",
    "Number of documents: 67743\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-tractor",
   "metadata": {},
   "source": [
    "### Get temp file location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-drove",
   "metadata": {},
   "source": [
    "I want to read these json files and save its content into txt temp files so that it can be deleted after it gets closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opened-national",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/vnbr1nbs5pv86wd58cwl_mxm0000gn/T\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "print(tempfile.gettempdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-profile",
   "metadata": {},
   "source": [
    "## 3. Using the age predictor model and upload to firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "resistant-muscle",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf778a0a883647f1b0b78675111dc62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, subprocess, shlex, urllib, re, json, requests, tempfile\n",
    "from ftfy import fix_text\n",
    "from tqdm.notebook import tqdm\n",
    "cwd = os.getcwd()\n",
    "\n",
    "PATH = '../../data/separated_by_email/'\n",
    "FIREBASE_URL = 'https://dsci-550-default-rtdb.firebaseio.com/'\n",
    "FIREBASE_TASK5_URL = urllib.parse.urljoin(FIREBASE_URL, 'assignment-1/task-5-additional-features/')\n",
    "\n",
    "t = tqdm(os.listdir(PATH))\n",
    "for email in t:\n",
    "    if email.startswith('.'):\n",
    "        continue\n",
    "    t.set_description(f'Processing {email}')\n",
    "    # the reading and cleaning processing is the same as before:\n",
    "    j = json.load(open(os.path.join(PATH, email)))\n",
    "    if 'X-TIKA:content' not in j:\n",
    "        print(email, \"does not have 'X-TIKA:content' key\")\n",
    "        continue\n",
    "    text = j['X-TIKA:content']\n",
    "    text_cleaned = fix_text(text).strip()\n",
    "    text_cleaned = re.sub(r'(\\n\\s*)+', ' ', text_cleaned) # replace multiple newlines to single newline\n",
    "    text_cleaned = re.sub(r'\\S*@\\S*\\s?', ' ', text_cleaned) # remove email addresses so that the QA model may perfrom well\n",
    "    text_cleaned = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', text_cleaned) #\n",
    "    \n",
    "    f = tempfile.NamedTemporaryFile(mode='w+', suffix='.txt')\n",
    "    f.write(text_cleaned)\n",
    "    f.seek(0)\n",
    "    tmpFileLoc = f.name\n",
    "    \n",
    "    # command1: age classify\n",
    "    command1 = f\"export SPARK_HOME='../spark-2.0.0-bin-hadoop2.7'; bin/authorage AgeClassify {os.path.join(cwd, 'Downloads/AgePredictor/', 'model/anthony-ageClassify.bin')} {tmpFileLoc} < {tmpFileLoc}\"\n",
    "    result = subprocess.Popen(command1, \n",
    "                              shell = True, \n",
    "                              stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "                              cwd=os.path.join(cwd, 'Downloads/AgePredictor/'), \n",
    "                              executable='/bin/sh')\n",
    "    out, err = result.communicate()\n",
    "    ageClassify = out.decode('utf-8').split('\\n')[1]\n",
    "    \n",
    "    # command2: age predict\n",
    "    command2 = f\"export SPARK_HOME='../spark-2.0.0-bin-hadoop2.7'; bin/authorage AgePredict {os.path.join(cwd, 'Downloads/AgePredictor/', 'model/anthony-ageClassify.bin')} {os.path.join(cwd, 'Downloads/AgePredictor/', 'model/regression-global.bin')} {tmpFileLoc} < {tmpFileLoc} 2>&1 | grep 'Prediction'\"\n",
    "    result = subprocess.Popen(command2, \n",
    "                              shell = True, \n",
    "                              stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "                              cwd=os.path.join(cwd, 'Downloads/AgePredictor/'), \n",
    "                              executable='/bin/sh')\n",
    "    out, err = result.communicate()\n",
    "    agePredict = re.findall(r'\\d.*',out.decode('utf-8'))\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    url = urllib.parse.urljoin(FIREBASE_TASK5_URL, email)\n",
    "    \n",
    "    uploadJSON = {'attacker estimated age': {'age classify': ageClassify, 'age prediction': agePredict}}\n",
    "    \n",
    "#     upload to firebase\n",
    "#     requests.patch(url, json = uploadJSON)\n",
    "    json.dump(uploadJSON, open(f'Downloads/{email}','w'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-progress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-wyoming",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-gender",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci550-assignment1",
   "language": "python",
   "name": "dsci550-assignment1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
